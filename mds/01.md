# Spark


## 快速上手之wordCount功能实现

![](https://oscimg.oschina.net/oscnet/up-0c64b47d7af8385dab48cc4ac0fc2aa1199.png)

实现wordCount逻辑图展示如上 👆

**搭建项目的时候，找不到依赖的话，可以到这个网站去下载**
``https://search.maven.org``  

完整代码可以查看下面 👇  
`com.ibli.spark.core.wc.Spark01_WordCount`


另一种wordCount的写法  
![](https://oscimg.oschina.net/oscnet/up-c8ab6d09a7417d8d85b662f553964c4a3a1.png)  

完整代码可以查看下面 👇  
`com.ibli.spark.core.wc.Spark02_WordCount`  

使用Spark提供的方法实现wordCount  

完整代码可以查看下面 👇  
`com.ibli.spark.core.wc.Spark03_WordCount`


## 使用spark-shell计算wordCount

### 进入到spark安装目录的bin路径下，执行一下命令：

```
sh spark-shell start
```
出现如下则启动成功： 

<img src="https://oscimg.oschina.net/oscnet/up-cd7305f89679f6dbc7e337a14f46ed459b8.png" width="600" height="350">

然后准备一个文件，路径和内容如下所示：

```shell script
gaolei@gaolei data % pwd
/usr/local/spark/data
gaolei@gaolei data % ls
graphx    mllib     streaming word.txt
gaolei@gaolei data % cat word.txt 
hello java
hello scala
hello spark
gaolei@gaolei data % 
```

然后在spark-shell模式下，输入一下代码：

```scala 3
sc.textFile("../data/word.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect
```

显示如下面： 

<img src="https://oscimg.oschina.net/oscnet/up-d656cf3da6b5bec7c95b9f59a9ea538328e.png" width="600" height="340">


**视频链接**： https://www.bilibili.com/video/BV11A411L7CK?p=11&spm_id_from=333.1007.top_right_bar_window_history.content.click



## 任务监控UI

因为是在本地起的spark实例，这里直接访问本地的4040端口：

<img src="https://oscimg.oschina.net/oscnet/up-4e7abfaf0bee923da6c5ee6140f90845177.png" height="630" width="490">

还可以查看job的详细执行信息: 

<img src="https://oscimg.oschina.net/oscnet/up-86f501a1031cf0711d5abf177c6300cd411.png" width="630" height="490">


## 通过 spark-submit提交job

```scala 3
sudo sh spark-submit \
--class org.apache.spark.examples.SparkPi \
--master local[2] \
../examples/jars/spark/spark-examples_2.12-3.0.0-preview2.jar \
5
```
运行结果：  

<img src="https://oscimg.oschina.net/oscnet/up-d719b7748a5561027c40b6b20c4e39f44cd.png" width="630" height="490"> 

**视频链接: ** https://www.bilibili.com/video/BV11A411L7CK?p=12&spm_id_from=pageDriver


## Spark standalone模式

### 修改 slaves.template
```scala 3
mv slaves.template slaves
vim slaves
```
添加worker节点
```scala 3
node1
node2
node3
```

### 修改spark-env.template
同样去掉template
然后编辑文件，添加如下配置，

```shell script
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home
export SPARK_MASTER_HOST=node1
export SPARK_MASTER_PORT=7077
```

查看JAVA_HOME : `echo $JAVA_HOME`

> 在node2 node3服务器上做相同对应配置然后，启动集群
>

```shell script
cd sbin
./start-all.sh
```

### 查看master UI监控页面

<img src="https://oscimg.oschina.net/oscnet/up-79b2a79855f1fbea46ad28da775f6a3b5c6.png" width="600" height="340">

然后向集群中提交任务的命令如下：

```scala 3
sudo sh spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://node1:7077 \
../examples/jars/spark/spark-examples_2.12-3.0.0-preview2.jar \
5
```

执行结果和上面一样。  

**视频地址: ** https://www.bilibili.com/video/BV11A411L7CK?p=13



