# 5. Spark 运行结构


Spark框架的核心是一个计算引擎，整体来说，它采用了标准的Master-Slave结构。

如下图所示：

<img src="https://oscimg.oschina.net/oscnet/up-bd217f3848a518d483c0b209bc736d22395.png">

- Master负责整个集群中的作业调度。
- Executor则是slave节点，负责实际执行任务。

## 运行时两大核心组件

### Driver

Spark驱动器节点，用于执行Spark任务中的main方法，负责实际代码的执行工作。
- 将用户程序转换成作业（Job）
- 在Executor之间调度任务（Task）
- 跟踪Executor的执行情况
- 通过UI展示查询运行情况

### Executor

Executor是集群中工作节点（Worker）中的一个JVM进程，负责在Spark作业中运行具体的任务（Task），
任务彼此之间相互独立。Spark应用启动时，Executor节点同时启动，并且伴随整个Spark应用的生命周期而存在。
如果有Executor节点发生了崩溃或故障，Spark应用也可以继续执行，会将出错节点的任务调度到其他的Executor节点
上继续运行。

**核心功能:**

- 负责运行组成Spark应用的任务，并将结果返回给驱动器进程
- 通过自身的块管理器为用户程序中要求缓存的RDD提供内存式存储，RDD是直接缓存在Executor进程内，
因此任务在运行时充分利用缓存数据加速运算。


## Master & Worker

- 集群的**独立部署环境**下，不需要依赖其他的资源调度框架，自己就可以实现资源调度功能
- Master负责资源的调度和分配，并进行集群的监控等功能
- Worker运行在集群的一个服务器上，由Master分配资源对数据进行并行的处理和计算。



## ApplicationMaster

Hadoop用户向YARN集群提交应用程序时，提交程序中应该包含ApplicationMaster，用于向资源调度器申请
执行任务的资源容器Container，运行用户自己的程序任务job，监控整个任务的执行，跟踪整个任务的状态，处理任务失败的
异常情况。

就是资源和计算之间解耦合的功能。


## 核心概念

### Executor & Core

<img src="https://oscimg.oschina.net/oscnet/up-63bc08491317300b4e1a39049f0024c3c4a.png">

| 名称 | 说明 |
| ---- | ---- | 
| --num-executors | 配置executors的数量 |
| --executor-memory | 配置executor内存大小 |
| --executor-cores | 配置executor 虚拟的CPU 核数 |




### 并行度

<img src="https://oscimg.oschina.net/oscnet/up-008ccc8227206e9044dac8b9650c79deee1.png">


### 有向无环图

<img src="https://oscimg.oschina.net/oscnet/up-d150380486fceeeae59c077240326bbc9e7.png" width="500" height="400">

**主要作用还是在任务调度方面。**

## 提交流程

下面是基于yarn环境的提交流程图：  

<img src="https://oscimg.oschina.net/oscnet/up-851400d2ff030412c83c9698af6fa3b29bc.png">  


### 两个方面： 

- 资源的申请
- 任务的计算

































